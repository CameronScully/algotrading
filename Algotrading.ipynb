{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning headline analysis to predict daily stock movement\n",
    "## Goal\n",
    "- When should we buy and sell stocks for profit\n",
    "\n",
    "## Stratergy\n",
    "- Load comment data from reddit\n",
    "- create sentimate label for each day\n",
    "- merge with market data\n",
    "- run classfication and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Sentimate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Machine learning\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phoebe\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (3,5,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "wsb = pd.read_csv('wallstreetbets_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upvotes, awards, and number of replies could also be valuable here in the future\n",
    "wsb_df = wsb_df[['body', 'timestamp', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13476652/13476652 [28:02<00:00, 8009.53it/s] \n"
     ]
    }
   ],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "errors = 0\n",
    "scores=[]\n",
    "for item in tqdm(wsb_df['body']):\n",
    "    sentiment_score=0\n",
    "    try:\n",
    "        sentiment_score=sentiment_score+analyser.polarity_scores(item)['compound']\n",
    "    except TypeError:\n",
    "        errors = errors+1\n",
    "        sentiment_score=0\n",
    "    \n",
    "    scores.append(sentiment_score)\n",
    "    \n",
    "wsb_df['sentiment_score'] = scores\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb_df.rename(columns={'timestamp': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>Date</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a fantastic idea Ill toss mine up in a...</td>\n",
       "      <td>2012-04-11 16:46:43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC is on 417</td>\n",
       "      <td>2012-04-11 17:39:08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>straddle call straddle put put put straddle ca...</td>\n",
       "      <td>2012-04-11 18:02:31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GMCR falls GOOG falls slightly GRPN will go in...</td>\n",
       "      <td>2012-04-11 18:47:11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CROX 426\\n\\nBZH 51\\n\\nim expecting both to bea...</td>\n",
       "      <td>2012-04-11 19:44:33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body                 Date  \\\n",
       "0  This is a fantastic idea Ill toss mine up in a...  2012-04-11 16:46:43   \n",
       "1                                     INTC is on 417  2012-04-11 17:39:08   \n",
       "2  straddle call straddle put put put straddle ca...  2012-04-11 18:02:31   \n",
       "3  GMCR falls GOOG falls slightly GRPN will go in...  2012-04-11 18:47:11   \n",
       "4  CROX 426\\n\\nBZH 51\\n\\nim expecting both to bea...  2012-04-11 19:44:33   \n",
       "\n",
       "   score  sentiment_score  \n",
       "0    2.0          -0.0772  \n",
       "1    2.0           0.0000  \n",
       "2    1.0           0.5023  \n",
       "3    6.0          -0.5994  \n",
       "4    1.0           0.0000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "0.5253936722273945\n"
     ]
    }
   ],
   "source": [
    "tickers = pd.read_excel('Tickers.xlsx')\n",
    "\n",
    "#filtered_tickers = tickers[tickers['Country'] == 'Australia']\n",
    "filtered_tickers = tickers\n",
    "\n",
    "count = 0\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for ticker in filtered_tickers['Ticker']:\n",
    "    #1. process stock\n",
    "    stock = pd.read_csv('Data/Data/'+ticker+'/'+ticker+'.csv')\n",
    "    \n",
    "    if stock.empty:\n",
    "        continue\n",
    "        \n",
    "    stock = stock.dropna()\n",
    "    \n",
    "    if stock.shape[0] < 100:\n",
    "        continue\n",
    "    \n",
    "    #format\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'])\n",
    "    \n",
    "    #attach label\n",
    "    stock['Label'] = (stock['Close'] < stock.shift(periods=-1)['Open']).astype(int)\n",
    "    stock.drop(stock.tail(1).index,inplace=True)\n",
    "    \n",
    "    stock_label_count = stock[\"Label\"].value_counts()\n",
    "    \n",
    "    #ignor unblanaced stocks\n",
    "    if (abs(stock_label_count[0] - stock_label_count[1]) / stock_label_count[0]) > 0.2:\n",
    "        continue\n",
    "        \n",
    "    #attach features for each day or drop days with missing features\n",
    "    df = pd.merge(wsb_df, stock[['Date','Label']], on='Date')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[df.loc[:, df.columns != 'Label']],\n",
    "        df['Label'],\n",
    "        random_state = 42,\n",
    "        stratify = df['Label'])\n",
    "    \n",
    "    model = MultinomialNB(alpha=0.1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    model_predict = model.predict(X_test)\n",
    "    \n",
    "    #evaluate(model_predict, y_test)\n",
    "    score = metrics.balanced_accuracy_score(y_test, model_predict)\n",
    "    \n",
    "    if best_score < score:\n",
    "        best_score = score\n",
    "    \n",
    "    print(count)\n",
    "    \n",
    "    count = count+1\n",
    "    \n",
    "    if count > 20:\n",
    "        break\n",
    "\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['headline_text'],\n",
    "        df['Label'],\n",
    "        random_state = 42,\n",
    "        stratify = df['Label'])\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': [1, 1e-1, 1e-2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, cv=10, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_search.best_score_) \n",
    "print('Best Params: ', grid_search.best_params_)\n",
    "\n",
    "\n",
    "loss = ['hinge', 'log', 'modified_huber', 'squared_hinge','perceptron']\n",
    "penalty = ['l1', 'l2', 'elasticnet'] \n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] \n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive'] \n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
    "eta0 = [1, 10, 100] \n",
    "\n",
    "param_distributions = dict(loss=loss,\n",
    "                           penalty=penalty,\n",
    "                           alpha=alpha, \n",
    "                           learning_rate=learning_rate, \n",
    "                           class_weight=class_weight, \n",
    "                           eta0=eta0) \n",
    "\n",
    "random = RandomizedSearchCV(estimator=sgd,\n",
    "                            param_distributions=param_distributions,\n",
    "                            scoring='roc_auc',\n",
    "                            verbose=1, n_jobs=-1, \n",
    "                            n_iter=100) \n",
    "\n",
    "random.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', random.best_score_) \n",
    "print('Best Params: ', random.best_params_)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
